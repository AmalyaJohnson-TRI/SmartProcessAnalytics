"""
Original work by Weike (Vicky) Sun vickysun@mit.edu/weike.sun93@gmail.com, https://github.com/vickysun5/SmartProcessAnalytics
Modified by Pedro Seber, https://github.com/PedroSeber/SmartProcessAnalytics
"""
from pandas import read_excel, read_csv
import numpy as np
from dataset_property_new import nonlinearity_assess, collinearity_assess, residual_analysis, nonlinearity_assess_dynamic
from sklearn.preprocessing import StandardScaler
from copy import deepcopy
from os.path import splitext
import matplotlib as mpl
mpl.style.use('default')
import warnings
warnings.filterwarnings('ignore')
import pdb

def main_SPA(main_data, test_data = None, interpretable = False, continuity = False, group_name = None, spectral_data = False,
            plot_interrogation = False, enough_data = False, nested_cv = False, robust_priority = False, dynamic_model = False, lag = 0,
            alpha = 0.01, cat = None, xticks = None, yticks = ['y'], model_name = None, cv_method = None, K_fold = 5, Nr = 10, alpha_num = 20,
            degree = [1, 2, 3], num_outer = 10, K_steps = 1, RNN_activation = ['relu'], RNN_layers = None, RNN_cell = ['basic'], RNN_batch_size = 1,
            RNN_epoch_overlap = None, RNN_past_steps = 10, RNN_max_checks_without_progress = 50, RNN_learning_rate = 1e-3,
            RNN_lambda_l2_reg = 1e-3, RNN_num_epochs = 200):
    """
    The main SPA function, which calls all other functions needed for model building.

    Parameters
    ----------
    main_data : string
        The path to the file containing your training data.
        The data should be N x (m+1), where the last column contains the predicted variable.
    test_data : string, optional, default = None
        The path to the file containing your test data.
        If None, the main_data is also used as test data (not recommended).
    interpretable : boolean, optional, default = False
        Whether you require the model to be interpretable.
    continuity : boolean, optional, default = False
        Whether you require the model to be continuous, such as for use in optimizers.
    group_name : string or None, optional, default = None
        The path to the file containing group labels for each variable (Nx1).
        Data may be grouped, for example, due to replicated measurements.
        If your data are not grouped, leave as None.
    spectral_data : boolean, optional, default = False
        Whether your data are spectral data.
        Note spectral data force the use of linear models.
    plot_interrogation : boolean, optional, default = False
        Whether SPA should generate plots of the data interrogation results. 
    enough_data : boolean, optional, default = False
        Whether you believe you have enough data to capture the complexities of your system.
    nested_cv : boolean, optional, default = False
        Whether to used nested cross-validation.
        Relevant only when enough_data == False.
    robust_priority : boolean, optional, default = False
        Whether to prioritize robustness over accuracy.
        Relevant only when enough_data == False.
    dynamic_model : boolean, optional, default = False
        Whether to use a dynamic model.
    lag : integer, optional, default = 0
        The lag used when assessing nonlinear dynamics.
        Relevant only when dynamic_model == True.
    alpha : float, optional, default = 0.01
        Significance level when doing statistical tests
    cat : list of int or None, optional, default = None
        Which variables are categorical. None represents no categorical variables.
        e.g.: [1, 0, 0] indicates only the first out of 3 variables is categorical.
    xticks : list of str or None, optional, default = None
        The names used to label x variables in plots generated by SPA.
        If None, SPA uses x1, x2, x3... as default values.
    yticks : list of str, optional, default = ['y']
        A single name to label the y variable in plots generated by SPA.
    model_name : list of str or None, optional, default = None
        The name of the model(s) you want SPA to evaluate.
        Each entry must be in {'OLS', 'ALVEN', 'SVR', 'RF', 'EN', 'SPLS', 'RR', ...
            'PLS', 'DALVEN', 'DALVEN_full_nonlinear', 'RNN', 'SS'}.
        If None, SPA determines which models are viable based on the data.
    cv_method : str or None, optional, default = None
        Which cross validation method to use.
        Each entry must be in {'Single', 'KFold', 'MC', 'Re_KFold'} when dynamic_model == False ...
            or {'Single_ordered', 'Timeseries', 'AIC', 'AICc', 'BIC'} when dynamic_model == True.
    K_fold : int, optional, default = 5
        Number of folds used in cross validation.
    Nr : int, optional, default = 10
        Number of CV repetitions used when cv_method in {'MC', 'Re_KFold', 'GroupShuffleSplit'}.
    alpha_num : int, optional, default = 20
        Penalty weight used when model_name in {'RR', 'EN', 'ALVEN', 'DALVEN', 'DALVEN_full_nonlinear'}.
    degree : list of int, optional, default = [1]
        The degrees of nonlinear mapping.
        Relevant only when model_name == 'DALVEN' or 'DALVEN_full_nonlinear'
    num_outer : int, optional, default = 10
        Number of outer loops used in nested CV.
        Relevant only when nested_cv == True.
    K_steps : int, optional, default = 1
        Number of future steps for training and test predictions.
        Relevant only when dynamic_model == True
    RNN_activation : list of str, optional, default = ['relu']
        The activation function(s) used to build an RNN.
        Each entry must be in {'relu', 'tanh', 'sigmoid', 'linear'}.
        If multiple values, all are tested against the validation set ...
            and the best is selected.
        All 'RNN_' parameters are relevant only when model_name == 'RNN'
    RNN_layers : array, optional, default = None
        An array with the number of neurons in each layer.
        The length of this array is the number of hidden layers.
        If None, is automatically set to [X_train.shape[1]] = m.
    RNN_cell : list of str, optional, default = ['basic']
        The cell type(s) of the RNN.
        Each entry must be in {'basic', 'GNN', 'LSTM'}.
        If multiple values, all are tested against the validation set ...
            and the best is selected.
    RNN_batch_size : int, optional, default = 1
        The batch size used when training the RNN.
    RNN_epoch_overlap : int or None, optional, default = None
        The space between two different training batches.
        If None, there is no overlap, and all batches use different data.
    RNN_past_steps : int, optional, default = 10
        The number of past steps the RNN can use.
    RNN_max_checks_without_progress : int, optional, default = 50
        How many steps without improvement in the validation score ...
            can occur before stopping early.
    RNN_learning_rate : float, optional, default = 1e-3
        The learning rate used when training the RNN.
    RNN_lambda_l2_reg : float, optional, default = 1e-3
        The weight of the L2 regularization penalty.
    RNN_num_epochs : int, optional, default = 200
        The number of RNN training epochs.
    """
    # Loading group (the actual data) from group_name (a path)
    if group_name:
        group = load_file(group_name)
    else:
        group = None

    # Loading the data
    Data = load_file(main_data)
    X_original = Data[:,:-1]
    y_original = Data[:,-1].reshape(-1,1)
    m = np.shape(X_original)[1]
    N = np.shape(X_original)[0]

    if test_data:
        Test_data = load_file(test_data)
        X_test_original = Test_data[:,:-1]
        y_test_original = Test_data[:,-1].reshape(-1,1)
        N_test = np.shape(X_test_original)[0]
    else:
        X_test_original = None
        y_test_original = None

    # Ensuring the user didn't pass too many cat or plot labels by mistake
    if isinstance(cat, (list, tuple)):
        cat = cat[:m]
    if isinstance(xticks, (list, tuple)):
        xticks = xticks[:m]
    if isinstance(yticks, (list, tuple)):
        yticks = yticks[:1] # [:1] returns a one-element list, while [0] returns the object

    # Determining nonlinearity and multicollinearity automatically
    round_number = 0
    nonlinear = nonlinearity_assess(X_original, y_original, plot_interrogation, cat = cat, alpha = alpha, difference = 0.4, xticks = xticks, yticks = yticks, round_number = round_number)
    multicollinear = collinearity_assess(X_original, y_original, plot_interrogation, xticks =  xticks, yticks = yticks, round_number = round_number) # Had an int() call
    if not nonlinear and dynamic_model:
        nonlinear_dynamic = nonlinearity_assess_dynamic(X_original, y_original, plot_interrogation, alpha = alpha, difference = 0.4, xticks = xticks, yticks = yticks, round_number = round_number, lag = lag)
        if nonlinear_dynamic:
            nonlinear = True

    # Selecting a model
    if model_name is None:
        if nonlinear:
            # Nonlinear, nondynamic models
            if not dynamic_model:
                model_name = ['ALVEN']
                if not enough_data or interpretable:
                    print(f'As {"your data are limited"*(not enough_data)}{" and "*(not(enough_data) and interpretable)}{"you require an interpretable model"*interpretable}, only ALVEN will be used.')
                elif continuity:
                    print('As you have enough data, do not require the model to be interpretable, and require continuity, ALVEN and SVR will be tested')
                    model_name.append('SVR')
                else:
                    print('As you have enough data, do not require the model to be interpretable, and do not require continuity, ALVEN, SVR, and RF will be tested')
                    model_name.append('SVR')
                    model_name.append('RF')
            # Nonlinear, dynamic models
            elif not enough_data or interpretable:
                print(f'As {"your data are limited"*(not enough_data)}{" and "*(not(enough_data) and interpretable)}{"you require an interpretable model"*interpretable}, DALVEN will be used.')
                model_name = ['DALVEN']
            else:
                print('As you have enough data and do not require the model to be interpretable, an RNN will be used.')
                model_name = ['RNN']
        # Linear, nondynamic models
        elif not dynamic_model:
            if not multicollinear:
                print('As there is no significant nonlinearity and multicollinearity in the data, OLS will be used.')
                model_name = ['OLS']
            elif spectral_data:
                print('As you have spectral data, RR and PLS will be used.')
                model_name = ['RR','PLS']
            elif interpretable:
                print('As you require an interpretable model, EN and SPLS will be used.')
                model_name = ['EN','SPLS']
            else:
                print('As your data have significant multicollinearity and you do not require an interpretable model, EN, SPLS, RR, and PLS will be used.')
                model_name = ['EN','SPLS','RR','PLS']
        # Linear dynamic model
        else:
            print('As your data have significant dynamics and multicolinearity, SS will be used.') # Originally CVA, SSARX, and MOSEP
            model_name = ['SS']

    # Cross-Validation Strategy
    if cv_method is None:
        if not dynamic_model:
            if enough_data:
                cv_method = f'Single{"_group"*bool(group_name)}'
                print(f'Single {"grouped CV "*bool(group_name)}{"validation "*(not bool(group_name))}will be used.') # Single grouped CV or single validation set
            elif group_name is None:
                cv_method = 'Re_KFold'
                print(f'{"Nested "*nested_cv}CV with repeated KFold in inner loop {"and one-std rule "*robust_priority}will be used.')
            else:
                cv_method = 'GroupKFold'
                print(f'{"Nested "*nested_cv}GroupKFold {"with one-std rule "*robust_priority}will be used.')
        # Dynamic models
        elif model_name == ['SS']:
            print('MATLAB/ADAPTx packges with information criterion will be used.')
        elif enough_data:    
            cv_method = 'Single_ordered'
            print('Single validation for time series will be used.')
        elif nested_cv:
            cv_method = 'Timeseries'
            print('Cross-validation for time series {"with one-std rule "*robust_priority}will be used.')
        elif X_original.shape[0]//X_original.shape[1]<40:
            cv_method = 'AICc'
            print('AICc information criteria will be used.')
        else:
            cv_method = 'AIC'
            print('AIC information criteria will be used.')

    # Preprocessing the data
    round_number = 1
    X = deepcopy(X_original)
    y = deepcopy(y_original)

    scaler_x = StandardScaler(with_mean=True, with_std=True)
    scaler_x.fit(X)
    X_scale = scaler_x.transform(X)
    scaler_y = StandardScaler(with_mean=True, with_std=True)
    scaler_y.fit(y)
    y_scale = scaler_y.transform(y)

    if X_test_original is not None:
        X_test = deepcopy(X_test_original)
        y_test = deepcopy(y_test_original)
        X_test_scale = scaler_x.transform(X_test)
        y_test_scale = scaler_y.transform(y_test) 
    else:
        X_test = X
        y_test = y
        X_test_scale = X_scale
        y_test_scale = y_scale

    # Model fitting - 1st round
    fitting_result = {}

    if 'OLS' in model_name:
        from regression_models import OLS_fitting
        final_model, model_params, mse_train, mse_test, yhat_train, yhat_test = OLS_fitting(X_scale, y_scale, X_test_scale, y_test_scale, 0)
        fitting_result['OLS'] = {'final_model':final_model, 'model_params':model_params, 'mse_train':mse_train, 'mse_test':mse_test, 'yhat_train':yhat_train, 'yhat_test':yhat_test}
        selected_model = 'OLS'
       
        # Determing whether a dynamic model should have been used
        yhat_test = scaler_y.inverse_transform(fitting_result[selected_model]['yhat_test'])
        _, dynamic_model = residual_analysis(X_test, y_test, yhat_test, plot = plot_interrogation, alpha = alpha, round_number = round_number)
        if dynamic_model:
            print('A residual analysis found dynamics in the system. Please run SPA again with dynamic_model = True')
        else:
            print('--------------Analysis Is Done--------------') 
        return fitting_result, selected_model
    elif not dynamic_model:
        global cv # So that run_cv_nondynamic has access to this import
        # Importing the correct CV settings based on robust_priority (one std rule)
        if not robust_priority:
            import cv_final as cv
        else:
            import cv_final_onestd as cv

        # Static / traditional CV
        if not nested_cv:
            val_err = np.zeros(len(model_name))
            temp_fitting_result = {}
            for index, model_index in enumerate(model_name):
                print(f'Running validation on model {model_index}', end = '\r')
                temp_fitting_result[model_index], val_err[index] = run_cv_nondynamic(model_index, X, y, X_scale, y_scale, X_test, y_test, X_test_scale, y_test_scale, cv_method, group, K_fold, Nr, alpha_num)
                print(f'Completed validation on model {model_index}')
                
            selected_model = model_name[np.argmin(val_err)]
            fitting_result[selected_model] = temp_fitting_result[selected_model]
        # Nested CV
        else: 
            if group_name is None:
                from sklearn.model_selection import train_test_split
                val_err = np.zeros((len(model_name),num_outer))

                for index_out in range(num_outer):
                    X_nest, X_nest_val, y_nest, y_nest_val = train_test_split(X, y, test_size=1/K_fold, random_state= index_out)
                    X_nest_scale, X_nest_scale_val, y_nest_scale, y_nest_scale_val = train_test_split(X_scale, y_scale, test_size=1/K_fold, random_state= index_out)
                    for index, model_index in enumerate(model_name):
                        val_err[index,index_out] = run_cv_nondynamic(model_index, X_nest, y_nest, X_nest_scale, y_nest_scale, X_nest_val, y_nest_val, X_nest_scale_val,
                                y_nest_scale_val, cv_method, group, K_fold, Nr, alpha_num, True)
            else:
                from sklearn.model_selection import LeaveOneGroupOut
                val_err = np.zeros((len(model_name), len(np.unique(group))))
                logo = LeaveOneGroupOut()

                for index_out, (train, val) in enumerate( logo.split(X, y.flatten(), groups=group.flatten()) ): # TODO: double-check train and val are right
                    for index, model_index in enumerate(model_name):
                        val_err[index,index_out] = run_cv_nondynamic(model_index, X[train], y[train], X_scale[train], y_scale[train], X[val], y[val], X_scale[val], y_scale[val],
                                cv_method, group[train], K_fold, Nr, alpha_num, True)
                    
            # Nested CV MSE results
            import matplotlib.pyplot as plt
            plt.figure()
            pos = [i+1 for i in range(len(model_name))]
            ax = plt.subplot(111)
            plt.violinplot(np.transpose(val_err))
            ax.set_xticks(pos)
            ax.set_xticklabels(model_name)
            ax.set_title('Testing MSE distribution using nested CV')
            plt.savefig('Violin_plot.png')

            # Final model fitting
            selected_model = model_name[np.argmin(np.mean(val_err,axis=1))]
            fitting_result[selected_model], _ = run_cv_nondynamic(selected_model, X, y, X_scale, y_scale, X_test, y_test, X_test_scale, y_test_scale, cv_method, group, K_fold, Nr, alpha_num)
                
        # Determing whether a dynamic model should have been used
        yhat_test = scaler_y.inverse_transform(fitting_result[selected_model]['yhat_test']) # TODO: should this yhat_test always be un-scaled?
        # TODO: Should y_test (and maybe X_test) be scaled before residual_analysis?
        _, dynamic_model = residual_analysis(X_test, y_test, yhat_test, plot = plot_interrogation, alpha = alpha, round_number = round_number)
        if dynamic_model:
            print('A residual analysis found dynamics in the system. Please run SPA again with dynamic_model = True')
        print('--------------Analysis Is Done--------------') 
        return fitting_result, selected_model
                    
    else: # Dynamic model
        if nonlinear:
            if model_name == ['RNN']:
                selected_model = 'RNN'
                import timeseries_regression_RNN as t_RNN
                if RNN_layers is None:
                    RNN_layers = [m]
                
                if 'IC' in cv_method:
                    import IC
                    if robust_priority and cv_method != 'BIC':
                        print(f'Note: BIC is recommended for robustness, but you selected {cv_method}.')
                    RNN_hyper, RNN_model, yhat_train_RNN, yhat_val_RNN, yhat_test_RNN, mse_train_RNN, mse_val_RNN, mse_test_RNN = IC.IC_mse('RNN', X_scale,
                            y_scale, X_test_scale, y_test_scale, cv_type = cv_method, cell_type = cell_type, activation = activation, RNN_layers = RNN_layers,
                            num_steps = num_steps, batch_size = batch_size, epoch_overlap = epoch_overlap, learning_rate = learning_rate,
                            lambda_l2_reg = lambda_l2_reg, num_epochs = num_epochs, max_checks_without_progress = max_checks_without_progress)
                elif not robust_priority:
                    import cv_final as cv
                    RNN_hyper, RNN_model, yhat_train_RNN, yhat_val_RNN, yhat_test_RNN, mse_train_RNN, mse_val_RNN, mse_test_RNN = cv.CV_mse('RNN', X_scale,
                            y_scale, X_test_scale, y_test_scale, cv_method, K_fold, Nr, cell_type = cell_type, group = group, activation = activation,
                            RNN_layers = RNN_layers, num_steps = num_steps, batch_size = batch_size, epoch_overlap = epoch_overlap, learning_rate = learning_rate,
                            lambda_l2_reg = lambda_l2_reg, num_epochs = num_epochs, max_checks_without_progress = max_checks_without_progress)
                else:
                    import cv_final_onestd as cv
                    RNN_hyper, RNN_model, yhat_train_RNN, yhat_val_RNN, yhat_test_RNN, mse_train_RNN, mse_val_RNN, mse_test_RNN = cv.CV_mse('RNN', X_scale,
                            y_scale, X_test_scale, y_test_scale, cv_method, K_fold, Nr, cell_type = cell_type, group = group, activation = activation,
                            RNN_layers = RNN_layers, num_steps = num_steps, batch_size = batch_size, epoch_overlap = epoch_overlap, learning_rate = learning_rate,
                            lambda_l2_reg = lambda_l2_reg, num_epochs = num_epochs, max_checks_without_progress = max_checks_without_progress)
                        
                fitting_result[selected_model] = {'model_hyper': RNN_hyper, 'final_model': RNN_model, 'mse_train': mse_train_RNN, 'mse_val': mse_val_RNN, 'mse_test': mse_test_RNN,
                        'yhat_train': yhat_train_RNN, 'yhat_val': yhat_val_RNN, 'yhat_test': yhat_test_RNN, 'MSE_val': MSE_val}
            else:
                selected_model = model_name
                if cv_method == 'IC':
                    import IC
                    if robust_priority and cv_method != 'BIC':
                        print(f'Note: BIC is recommended for robustness, but you selected {cv_method}.')
                    DALVEN_hyper, DALVEN_model, DALVEN_params, mse_train_DALVEN, mse_test_DALVEN, yhat_train_DALVEN, yhat_test_DALVEN, MSE_v_DALVEN, final_list = IC.IC_mse(model_name,
                            X, y, X_test, y_test, cv_type = IC_method, alpha_num = alpha_num, lag = lag, degree = degree, label_name = True, trans_type = 'auto')
                elif not robust_priority:
                    import cv_final as cv
                    DALVEN_hyper, DALVEN_model, DALVEN_params, mse_train_DALVEN, mse_test_DALVEN, yhat_train_DALVEN, yhat_test_DALVEN, MSE_v_DALVEN, final_list = cv.CV_mse(model_name,
                            X, y, X_test, y_test, cv_method, K_fold, Nr, alpha_num = alpha_num, label_name = True, trans_type = 'auto', degree = degree, lag = lag)
                else:
                    import cv_final_onestd as cv
                    DALVEN_hyper, DALVEN_model, DALVEN_params, mse_train_DALVEN, mse_test_DALVEN, yhat_train_DALVEN, yhat_test_DALVEN, MSE_v_DALVEN, final_list = cv.CV_mse(model_name,
                            X, y, X_test, y_test, cv_method, K_fold, Nr, alpha_num = alpha_num, label_name = True, trans_type = 'auto', degree = degree, lag = lag)
                
                fitting_result[selected_model] = {'model_hyper': DALVEN_hyper,'final_model': DALVEN_model, 'model_params': DALVEN_params , 'mse_train': mse_train_DALVEN,
                        'mse_val': MSE_v_DALVEN, 'mse_test': mse_test_DALVEN, 'yhat_train': yhat_train_DALVEN, 'yhat_test': yhat_test_DALVEN, 'final_list': final_list}
            print('--------------Analysis Is Done--------------')
            return fitting_result, selected_model
        
        else:
            import timeseries_regression_matlab as t_matlab
            
            maxorder = int(input('Maximum order number you want to consider: '))
            # MATLAB
            matlab_params, matlab_myresults, matlab_MSE_train, matlab_MSE_val, matlab_MSE_test, matlab_y_predict_train, matlab_y_predict_val, matlab_y_predict_test, matlab_train_error, matlab_val_error, matlab_test_error = t_matlab.timeseries_matlab_single(X, y, X_test = X_test, y_test= y_test, train_ratio = 1,\
                                                                                                                                                                                                                                                                 maxorder = maxorder, mynow = 1, steps = K_steps, plot = True)
            #adaptx
            ADAPTx = int(input('Do you installed ADAPTx software? [Yes: 1, No: 0] '))
            if ADAPTx:
                import timeseries_regression_Adaptx as t_Adaptx
        
                url = input('Url for the ADAPTx software (e.g. C:\\Users\\Vicky\\Desktop\\AdaptX\\ADAPTX35M9\\): ')
                data_url =  input('Saved data file URL for the ADAPTx software (e.g. C:\\Users\\Vicky\\Desktop\\AdaptX\\ADAPTX35M9\\test\\): ')
                mymaxlag = int(input('Maximum number of lags considered in ADAPTx: '))
                mydegs = [int(x) for x in input('Degree of trend t in ADAPTx [if not known use default -1 0 1]: ').split()]
                
                
                Adaptx_optimal_params, Adaptx_myresults, Adaptx_MSE_train, Adaptx_MSE_val, Adaptx_MSE_test, Adaptx_y_predict_train, Adaptx_y_predict_val, Adaptx_y_predict_test, Adaptx_train_error, Adaptx_val_error, Adaptx_test_error = t_Adaptx.Adaptx_matlab_single(X, y, data_url = data_url, url = url, X_test=X_test, y_test=y_test, train_ratio = 1,\
                                                                                                                                                    mymaxlag = mymaxlag, mydegs = mydegs, mynow = 1, steps = K_steps, plot = True)                     
                        
            
            if not ADAPTx: 
                print('The final state space model is fitted based on ' + matlab_params['method'][0] + ' using MATLAB.')
                selected_model = matlab_params['method'][0]
                yhat_test = matlab_y_predict_test.transpose()[:,0].reshape((-1,1))
                yhat_test = scaler_y.inverse_transform(yhat_test)
                
                fitting_result[selected_model] = {'model_hyper':matlab_params,'final_model':matlab_myresults, 'mse_train':matlab_MSE_train, 'mse_val':matlab_MSE_val, 'mse_test':matlab_MSE_test, 'yhat_train':matlab_y_predict_train, 'yhat_val':matlab_y_predict_val,'yhat_test':matlab_y_predict_test}

                residual_analysis(X_test, y_test,yhat_test, alpha = alpha, round_number = round_number)
                print('--------------Analysis Is Done--------------')
                
            else:
                print('The final state space model is selected based on minimum averaged MSE.')
                if np.mean(matlab_MSE_train) <= np.mean(Adaptx_MSE_train):
                    print('State space model by Matlab is selected. Model parameters is stored in matlab_params.')
                    print('The final state space model is fitted based on ' + matlab_params['method'][0] + ' using MATLAB.')
                    selected_model = matlab_params['method'][0]
                    
                    fitting_result[selected_model] = {'model_hyper':matlab_params,'final_model':matlab_myresults, 'mse_train':matlab_MSE_train, 'mse_val':matlab_MSE_val, 'mse_test':matlab_MSE_test, 'yhat_train':matlab_y_predict_train, 'yhat_val':matlab_y_predict_val,'yhat_test':matlab_y_predict_test}
                    
                    yhat_test = matlab_y_predict_test.transpose()[:,0].reshape((-1,1))
                    yhat_test = scaler_y.inverse_transform(yhat_test)

                    residual_analysis(X_test, y_test,yhat_test, alpha = alpha, round_number = round_number)
                    print('--------------Analysis Is Done--------------')
                    
                    
                else:
                    print('State space model by ADAPTx is selected. Model parameters is stored in Adaptx_optimal_params.')
                    selected_model = 'ADAPTx'
                    fitting_result[selected_model] = {'model_hyper':Adaptx_optimal_params,'final_model':Adaptx_myresults, 'mse_train':Adaptx_MSE_train, 'mse_val':Adaptx_MSE_val, 'mse_test':Adaptx_MSE_test, 'yhat_train':Adaptx_y_predict_train, 'yhat_val':Adaptx_y_predict_val,'yhat_test':Adaptx_y_predict_test}

                    yhat_test = Adaptx_y_predict_test.transpose()[Adaptx_optimal_params['lag'][0][0]:,0].reshape((-1,1))
                    yhat_test = scaler_y.inverse_transform(yhat_test)                
                    residual_analysis(X_test[Adaptx_optimal_params['lag'][0][0]:,:], y_test[Adaptx_optimal_params['lag'][0][0]:,0].reshape((-1,1)),yhat_test, alpha = alpha, round_number = round_number)
                    print('--------------Analysis Is Done--------------')




    ############################ model fitting 2nd round if necessary
#    if round_number == 2:
#        nonlinear_dynamic = int(input('Do you want to use a nonlinear dynamic model (Yes 1 No 0 Not sure 2): '))
#        if nonlinear_dynamic == 1:
#            nonlinear = 1
#        elif nonlinear_dynamic ==2:
#            nonlinear = nonlinearity_assess(X_original, y_original, plot_interrogation, cat = cat,alpha = alpha, difference = 0.4, xticks = xticks, yticks = yticks, round_number =  round_number)
#            if nonlinear == 0:
#                lag = int(input('The lag number you want to use to assess nonlinear dyanmics: '))
#                nonlinear_dynamic = nonlinearity_assess_dynamic(X_original, y_original, plot_interrogation, alpha = alpha, difference = 0.4, xticks = xticks, yticks = yticks, round_number =  round_number,lag= lag)
#                nonlinear = if_nonlinear or if_nonlinear_dynamic
#        else:
#            nonlinear == 0
#        print('')
#        print("""----------------------------------------------------
#    Based on the information of data characteristics, the following dynamic model is selected:
#    ----------------------------------------------------""")
#            
#        model_name = None
#                
#        if nonlinear == 1:
#            print('The nonlinear dynamic model is selected:')
#            if enough_data == 0 :
#                print('Because you have limited data, DALVEN is recommonded.')
#                model_name = ['DALVEN']
#            elif interpretable == 1:
#                print('Because you would like an interpretable model, DALVEN is recommonded.')
#                model_name = ['DALVEN']            
#            else:
#                print('Because you have engough data and do not require interpretability, RNN is recommonded.')
#                model_name = ['RNN']
#                
#        else:
#            print('There is significant dynamics and multicolinearity, CVA/SSARX/MOSEP are recommonded.')
#            model_name = ['SS']
#            
#        
#        print('')
#        print("""----------------------------------------------------
#    Based on the information of data characteristics, the following fitting strategy is selected:
#    ----------------------------------------------------""")
#            
#        if model_name == ['SS']:
#            print('MATLAB/ADAPTx packges with information criterion will be used')
#            
#        else:    
#            if enough_data:
#                cv_method = 'Single_ordered'
#                print('Single validation is used for time series modeling.')
#            else:
#                if nested_cv:
#                    if robust_priority:
#                        cv_method = 'Timeseries'
#                        print('Cross-validation for time series with one std rule is selected.')
#                                               
#                    else:
#                        cv_method = 'Timeseries'
#                        print('Cross-validation for time series is selected.')
#                else:
#                    cv_method = 'IC'
#                    print('Information criteria is selected.')
#            
#        print('')
#        print("""----------------------------------------------------
#    Start 2nd-Round Model Fitting
#    ----------------------------------------------------""")
#        steps = int(input('Number of steps you want to test for the future prediction? '))
#        
#        if nonlinear:
#            if model_name == ['RNN']:
#                selected_model = 'RNN'
#                import timeseries_regression_RNN as t_RNN
#                
#                print('Please input the following numbers/types from the smallest to the largest: 1 3 5 or linear relu')
#                activation = list(map(str,input("Types of activation function you want to use (e.g. linear, relu, tanh?): ").strip().split()))
#                num_layers = list(map(int,input("Numbers of layers you want to test: ").strip().split()))
#                state_size = list(map(int,input("Numbers of states you want to test: ").strip().split()))
#                cell_type = list(map(str,input("Types of cells you want to use (e.g. regular, LSTM, GRU?): ").strip().split()))
#
#                print('Please provide the following training parameter.')
#                batch_size = int(input("Number of batch used in training you want to test: "))
#                epoch_overlap = input('The overlap between different batch? The number indicate the space between two training, 0 means no space. If no overlap type None. ')
#                if epoch_overlap == 'None':
#                    epoch_overlap = None
#                else:
#                    epoch_overlap = int(epoch_overlap)
#                num_steps = int(input("Number of steps back in past of RNN you want to use : "))
#                max_checks_without_progress = int(input('How many steps for no improvment for early stopping?: '))
#                learning_rate = float(input('Learning rate? '))
#                lambda_l2_reg = float(input('Penalty weight of L2 norm? '))
#                num_epochs = float(input('Maximum number of epochs? ' ))
#                    
#                if cv_method == 'IC':
#                    import IC
#
#                    if robust_priority:
#                        print('BIC is recommended to prefer a simplier model for robustness.')
#                        
#                    IC_method = input('The type of information criterion you want to use (AIC, AICc, BIC), if not known type None, the criterion will be selected between AIC/AICc. ')
#                    if IC_method == 'None':
#                        IC_method = None
#                        
#        
#                    print('------Model Construction------')
#        
#                    RNN_hyper, RNN_model, yhat_train_RNN, yhat_val_RNN, yhat_test_RNN, mse_train_RNN, mse_val_RNN, mse_test_RNN= IC.IC_mse('RNN', X_scale, y_scale, X_test_scale, y_test_scale, cv_type = IC_method, cell_type = cell_type,\
#                                                                                                                                            activation = activation, num_layers=num_layers,state_size=state_size,num_steps=num_steps, \
#                                                                                                                                            batch_size=batch_size,epoch_overlap= epoch_overlap, learning_rate=learning_rate, lambda_l2_reg=lambda_l2_reg,\
#                                                                                                                                            num_epochs=num_epochs, max_checks_without_progress = max_checks_without_progress,round_number = str(round_number))
#                    
#                    
#
#                else:
#                    print('------Model Construction------')
#
#                    if not robust_priority:
#                        
#                        import cv_final as cv
#            
#                        RNN_hyper, RNN_model, yhat_train_RNN, yhat_val_RNN, yhat_test_RNN, mse_train_RNN, mse_val_RNN, mse_test_RNN= cv.CV_mse('RNN', X_scale, y_scale, X_test_scale, y_test_scale, cv_type = cv_method, K_fold = K_fold, Nr= Nr, cell_type = cell_type,group=group,\
#                                                                                                                                                activation = activation, num_layers=num_layers,state_size=state_size,num_steps=num_steps, \
#                                                                                                                                                batch_size=batch_size,epoch_overlap= epoch_overlap, learning_rate=learning_rate, lambda_l2_reg=lambda_l2_reg,\
#                                                                                                                                                num_epochs=num_epochs, max_checks_without_progress = max_checks_without_progress,round_number = str(round_number))
#                    else:
#                        import cv_final_onestd as cv_std    
#                        print('CV with ons-std rule is used for RNN model')
#
#            
#                        RNN_hyper, RNN_model, yhat_train_RNN, yhat_val_RNN, yhat_test_RNN, mse_train_RNN, mse_val_RNN, mse_test_RNN= cv_std.CV_mse('RNN', X_scale, y_scale, X_test_scale, y_test_scale, cv_type = cv_method, K_fold = K_fold, Nr= Nr, cell_type = cell_type,group=group,\
#                                                                                                                                                activation = activation, num_layers=num_layers,state_size=state_size,num_steps=num_steps, \
#                                                                                                                                                batch_size=batch_size,epoch_overlap= epoch_overlap, learning_rate=learning_rate, lambda_l2_reg=lambda_l2_reg,\
#                                                                                                                                                num_epochs=num_epochs, max_checks_without_progress = max_checks_without_progress,round_number = str(round_number))
#                   
#                        
#                     
#                fitting_result[selected_model] = {'model_hyper':RNN_hyper,'final_model':RNN_model, 'mse_train':mse_train_RNN, 'mse_val':mse_val_RNN, 'mse_test':mse_test_RNN, 'yhat_train':yhat_train_RNN, 'yhat_val':yhat_val_RNN, 'yhat_test':yhat_test_RNN, 'MSE_val': MSE_val}
#
#                #k-step prediction
#                num_train=round(X.shape[0]*RNN_hyper['early_stop']['train_ratio'])
#                
#                print('K-step prediction for training')
#                train_y_prediction_kstep, train_loss_kstep = t_RNN.timeseries_RNN_feedback_test(X_scale[:num_train], y_scale[:num_train], X_scale[:num_train],y_scale[:num_train], kstep = steps, cell_type=RNN_hyper['cell_type'],activation = RNN_hyper['activation'], state_size = RNN_hyper['state_size'],\
#                                                                                                                                          num_layers = RNN_hyper['num_layers'], location=RNN_model, plot=True,round_number = str(round_number))
#                print('K-step prediction for training')
#                test_y_prediction_kstep, test_loss_kstep = t_RNN.timeseries_RNN_feedback_test(X_scale[:num_train], y_scale[:num_train], X_test_scale,y_test_scale, kstep = steps, cell_type=RNN_hyper['cell_type'],activation = RNN_hyper['activation'], state_size = RNN_hyper['state_size'],\
#                                                                                                                                          num_layers = RNN_hyper['num_layers'], location=RNN_model, plot=True, round_number = str(round_number))
#                scaler_y_RNN = StandardScaler(with_mean=True, with_std=True)
#                scaler_y_RNN.fit(y_scale[:num_train])
#                yhat_test_RNN = scaler_y_RNN.inverse_transform(yhat_test_RNN)
#            
#                residual_analysis(X_test_scale, y_test_scale, yhat_test_RNN, alpha = alpha, round_number = round_number)
#                        
#                print('--------------Analysis Is Done--------------')
#
#                        
#                        
#                
#
#
#            else:
#                import regression_models as rm
#
#                alpha_num = int(input('Number of penalty weight you want to consider in DALVEN, if not known input 20: '))
#                degree = list(map(int,input("Orders of nonlinear mapping considered in DALVEN: (choose to include 1 2 3) ").strip().split()))
#
#                if int(input('Do you want to test both DALVEN-full/DALVEN? (Yes: 1, No: 0): ')):
#                    if cv_method == 'IC':
#                        import IC
#                        
#                        if robust_priority:
#                            print('BIC is recommended to prefer a simplier model for robustness.')
#                        
#                        IC_method = input('The type of information criterion you want to use (AIC, AICc, BIC), if not known type None, the criterion will be selected between AIC/AICc. ')
#
#                        print('------Model Construction------')
#                        
#                        DALVEN_hyper,DALVEN_model, DALVEN_params, mse_train_DALVEN, mse_test_DALVEN, yhat_train_DALVEN, yhat_test_DALVEN, MSE_v_DALVEN, final_list = IC.IC_mse('DALVEN', X, y, X_test, y_test, cv_type = IC_method, alpha_num=alpha_num, lag=lag, degree=degree, label_name=True, trans_type= 'auto')
#                        DALVEN_full_hyper,DALVEN_full_model, DALVEN_full_params, mse_train_DALVEN_full, mse_test_DALVEN_full, yhat_train_DALVEN_full, yhat_test_DALVEN_full, MSE_v_DALVEN_full, final_list_full = IC.IC_mse('DALVEN_full_nonlinear', X, y, X_test, y_test, cv_type = IC_method, alpha_num=alpha_num, lag=lag, degree=degree, label_name=True, trans_type= 'auto')
#        
#                    else:
#                        #using validation set
#                        if not robust_priority:
#                            import cv_final as cv
#        
#                            print('------Model Construction------')
#
#         
#                            DALVEN_hyper,DALVEN_model, DALVEN_params, mse_train_DALVEN, mse_test_DALVEN, yhat_train_DALVEN, yhat_test_DALVEN, MSE_v_DALVEN, final_list = cv.CV_mse('DALVEN', X, y, X_test, y_test, cv_type = cv_method, K_fold = K_fold, Nr= Nr, \
#                                                                                                                                                                                   alpha_num=alpha_num, label_name=True, trans_type= 'auto',degree=degree,lag = lag)
#                            DALVEN_full_hyper,DALVEN_full_model, DALVEN_full_params, mse_train_DALVEN_full, mse_test_DALVEN_full, yhat_train_DALVEN_full, yhat_test_DALVEN_full, MSE_v_DALVEN_full, final_list_full = cv.CV_mse('DALVEN_full_nonlinear', X, y, X_test, y_test, cv_type = cv_method, K_fold = K_fold, Nr= Nr, \
#                                                                                                                                                                                   alpha_num=alpha_num, label_name=True, trans_type= 'auto',degree=degree,lag = lag)                       
#                            
#                        
#                        else:
#                            print('CV with ons-std rule is used for DALVEN model')
#                            import cv_final_onestd as cv_std    
#                            
#                            print('------Model Construction------')
#         
#                            DALVEN_hyper,DALVEN_model, DALVEN_params, mse_train_DALVEN, mse_test_DALVEN, yhat_train_DALVEN, yhat_test_DALVEN, MSE_v_DALVEN, final_list = cv_std.CV_mse('DALVEN', X, y, X_test, y_test, cv_type = cv_method, K_fold = K_fold, Nr= Nr, \
#                                                                                                                                                                                   alpha_num=alpha_num, label_name=True, trans_type= 'auto',degree=degree,lag = lag)
#                            DALVEN_full_hyper,DALVEN_full_model, DALVEN_full_params, mse_train_DALVEN_full, mse_test_DALVEN_full, yhat_train_DALVEN_full, yhat_test_DALVEN_full, MSE_v_DALVEN_full, final_list_full = cv_std.CV_mse('DALVEN_full_nonlinear', X, y, X_test, y_test, cv_type = cv_method, K_fold = K_fold, Nr= Nr, \
#                                                                                                                                                                                   alpha_num=alpha_num, label_name=True, trans_type= 'auto',degree=degree,lag = lag)
#                    
#                    ##select the method
#                    if MSE_v_DALVEN <= MSE_v_DALVEN_full:
#                        selected_model = 'DALVEN'
#                    else:
#                        selected_model = 'DALVEN_full_nonlinear'
#                            
#                    print('Based on the ' + cv_method +', ' + selected_model +' is selected.')
#                                
#                                                   
#                    #DALVEN model evaluation after choosing the method
#                    if selected_model == 'DALVEN':
#                        DALVEN_mse_test_multi, DALVEN_yhat_test_multi= rm.DALVEN_testing_kstep(X, y, X_test, y_test, DALVEN_model,DALVEN_hyper['retain_index'], DALVEN_hyper['degree'], DALVEN_hyper['lag'] , steps,trans_type = 'auto',plot=True,round_number = str(round_number))
#                        DALVEN_mse_train_multi, DALVEN_yhat_train_multi= rm.DALVEN_testing_kstep(X, y, X, y, DALVEN_model,DALVEN_hyper['retain_index'], DALVEN_hyper['degree'], DALVEN_hyper['lag'] , steps,trans_type = 'auto',plot=True,round_number = str(round_number))
#
#                        lag_number = DALVEN_hyper['lag']
#                                        
#                        scalery = StandardScaler()
#                        scalery.fit(y[lag_number:])
#                                    
#                        yhat_test_DALVEN=scalery.inverse_transform(yhat_test_DALVEN)
#                             
#                        fitting_result[selected_model] = {'model_hyper':DALVEN_hyper,'final_model':DALVEN_model, 'model_params':DALVEN_params , 'mse_train':mse_train_DALVEN, 'mse_val':MSE_v_DALVEN, 'mse_test':mse_test_DALVEN, 'yhat_train':yhat_train_DALVEN, 'yhat_test':yhat_test_DALVEN, 'final_list': final_list}
#                                                  
#                        residual_analysis(X_test[lag_number:], y_test[lag_number:],yhat_test_DALVEN, alpha =alpha, round_number = round_number)
#                                      
#                    else:
#                                  
#                        DALVEN_full_mse_test_multi, DALVEN_full_yhat_test_multi= rm.DALVEN_testing_kstep_full_nonlinear(X, y, X_test, y_test, DALVEN_full_model,DALVEN_full_hyper['retain_index'], DALVEN_full_hyper['degree'], DALVEN_full_hyper['lag'] , steps ,trans_type = 'auto', plot=True,round_number = str(round_number))
#                        DALVEN_full_mse_train_multi, DALVEN_full_yhat_train_multi= rm.DALVEN_testing_kstep_full_nonlinear(X, y, X, y, DALVEN_full_model,DALVEN_full_hyper['retain_index'], DALVEN_full_hyper['degree'], DALVEN_full_hyper['lag'] , steps ,trans_type = 'auto', plot=True,round_number =str(round_number))
#                   
#                        lag_number = DALVEN_full_hyper['lag']
#                                        
#                        scalery = StandardScaler()
#                        scalery.fit(y[lag_number:])
#                                    
#                        yhat_test_DALVEN_full=scalery.inverse_transform(yhat_test_DALVEN_full)
#                             
#                        fitting_result[selected_model] = {'model_hyper':DALVEN_full_hyper,'final_model':DALVEN_full_model, 'model_params':DALVEN_full_params , 'mse_train':mse_train_DALVEN_full, 'mse_val':MSE_v_DALVEN_full, 'mse_test':mse_test_DALVEN_full, 'yhat_train':yhat_train_DALVEN_full, 'yhat_test':yhat_test_DALVEN_full, 'final_list': final_list_full}
#                               
#                        residual_analysis(X_test[lag_number:], y_test[lag_number:],yhat_test_DALVEN_full, alpha =alpha, round_number = round_number)
#                    print('--------------Analysis Is Done--------------')
#                else:
#                    DALVEN_method = input('Type in the method you want to test: DALVEN_full_nonlinear or DALVEN. ')
#                    selected_model = DALVEN_method
#                    if cv_method == 'IC':
#                        import IC
#                        if robust_priority:
#                            print('BIC is recommended to prefer a simplier model for robustness.')
#                        IC_method = input('The type of information criterion you want to use (AIC, AICc, BIC), if not known type None, the criterion will be selected between AIC/AICc. ')
#                        print('------Model Construction------')
#                        DALVEN_hyper,DALVEN_model, DALVEN_params, mse_train_DALVEN, mse_test_DALVEN, yhat_train_DALVEN, yhat_test_DALVEN, MSE_v_DALVEN,
#                                final_list = IC.IC_mse(DALVEN_method, X, y, X_test, y_test, cv_type = IC_method, alpha_num=alpha_num, lag=lag, degree=degree, label_name=True, trans_type= 'auto')
#                    else:
#                        # Using validation set
#                        print('------Model Construction------')
#                        if not robust_priority:
#                            import cv_final as cv
#                            DALVEN_hyper,DALVEN_model, DALVEN_params, mse_train_DALVEN, mse_test_DALVEN, yhat_train_DALVEN, yhat_test_DALVEN, MSE_v_DALVEN, final_list = cv.CV_mse(DALVEN_method, X, y, 
#                                    X_test, y_test, cv_type = cv_method, K_fold = K_fold, Nr= Nr, alpha_num=alpha_num, label_name=True, trans_type= 'auto',degree=degree,lag = lag)
#                        else:
#                            print('CV with ons-std rule is used for DALVEN model')
#                            import cv_final_onestd as cv_std    
#                            DALVEN_hyper,DALVEN_model, DALVEN_params, mse_train_DALVEN, mse_test_DALVEN, yhat_train_DALVEN, yhat_test_DALVEN, MSE_v_DALVEN, final_list = cv_std.CV_mse(DALVEN_method, X, y,
#                                    X_test, y_test, cv_type = cv_method, K_fold = K_fold, Nr= Nr, alpha_num=alpha_num, label_name=True, trans_type= 'auto',degree=degree,lag = lag)
#
#                    fitting_result[selected_model] = {'model_hyper':DALVEN_hyper,'final_model':DALVEN_model, 'model_params':DALVEN_params , 'mse_train':mse_train_DALVEN, 'mse_val':MSE_v_DALVEN,
#                                    'mse_test':mse_test_DALVEN, 'yhat_train':yhat_train_DALVEN, 'yhat_test':yhat_test_DALVEN, 'final_list': final_list}
#
#                    # Model evaluation
#                    if DALVEN_method == 'DALVEN':
#                        DALVEN_mse_test_multi, DALVEN_yhat_test_multi= rm.DALVEN_testing_kstep(X, y, X_test, y_test, DALVEN_model,DALVEN_hyper['retain_index'], DALVEN_hyper['degree'], DALVEN_hyper['lag'] , steps,trans_type = 'auto',plot=True,round_number = str(round_number))
#                        DALVEN_mse_train_multi, DALVEN_yhat_train_multi= rm.DALVEN_testing_kstep(X, y, X, y, DALVEN_model,DALVEN_hyper['retain_index'], DALVEN_hyper['degree'], DALVEN_hyper['lag'] , steps,trans_type = 'auto',plot=True,round_number = str(round_number))
#                            
#                    else:                              
#                        DALVEN_mse_test_multi, DALVEN_yhat_test_multi= rm.DALVEN_testing_kstep_full_nonlinear(X, y, X_test, y_test, DALVEN_model,DALVEN_hyper['retain_index'], DALVEN_hyper['degree'], DALVEN_hyper['lag'] , steps ,trans_type = 'auto', plot=True,round_number = str(round_number))
#                        DALVEN_mse_train_multi, DALVEN_yhat_train_multi= rm.DALVEN_testing_kstep_full_nonlinear(X, y, X, y, DALVEN_model,DALVEN_hyper['retain_index'], DALVEN_hyper['degree'], DALVEN_hyper['lag'] , steps ,trans_type = 'auto', plot=True,round_number =str(round_number))
#                   
#                    lag_number = DALVEN_hyper['lag']
#                                    
#                    scalery = StandardScaler()
#                    scalery.fit(y[lag_number:])
#                                
#                    yhat_test_DALVEN=scalery.inverse_transform(yhat_test_DALVEN)
#                    residual_analysis(X_test[lag_number:], y_test[lag_number:],yhat_test_DALVEN, alpha =alpha, round_number = round_number)
#            
#                    print('--------------Analysis Is Done--------------')
#                        
#                            
#
#                    
#        
#        else:
#            import timeseries_regression_matlab as t_matlab
#            
#            maxorder = int(input('Maximum order number you want to consider: '))
#            
#            print('------Model Construction------')
#            #matlab
#            matlab_params, matlab_myresults, matlab_MSE_train, matlab_MSE_val, matlab_MSE_test, matlab_y_predict_train, matlab_y_predict_val, matlab_y_predict_test, matlab_train_error, matlab_val_error, matlab_test_error = t_matlab.timeseries_matlab_single(X, y, X_test = X_test, y_test= y_test, train_ratio = 1,\
#                                                                                                                                                                                                                                                                 maxorder = maxorder, mynow = 1, steps = steps, plot = True)
#            #adaptx
#            ADAPTx = int(input('Do you installed ADAPTx software? [Yes: 1, No: 0] '))
#            if ADAPTx:
#                import timeseries_regression_Adaptx as t_Adaptx
#        
#                url = input('Url for the ADAPTx software (e.g. C:\\Users\\Vicky\\Desktop\\AdaptX\\ADAPTX35M9\\): ')
#                data_url =  input('Saved data file URL for the ADAPTx software (e.g. C:\\Users\\Vicky\\Desktop\\AdaptX\\ADAPTX35M9\\test\\): ')
#                mymaxlag = int(input('Maximum number of lags considered in ADAPTx: '))
#                mydegs = [int(x) for x in input('Degree of trend t in ADAPTx [if not known use default -1 0 1]: ').split()]
#                
#                
#                Adaptx_optimal_params, Adaptx_myresults, Adaptx_MSE_train, Adaptx_MSE_val, Adaptx_MSE_test, Adaptx_y_predict_train, Adaptx_y_predict_val, Adaptx_y_predict_test, Adaptx_train_error, Adaptx_val_error, Adaptx_test_error = t_Adaptx.Adaptx_matlab_single(X, y, data_url = data_url, url = url, X_test=X_test, y_test=y_test, train_ratio = 1,\
#                                                                                                                                                    mymaxlag = mymaxlag, mydegs = mydegs, mynow = 1, steps = steps, plot = True)                     
#                        
#            
#            if not ADAPTx: 
#                print('The final state space model is fitted based on ' + matlab_params['method'][0] + ' using MATLAB.')
#                selected_model = matlab_params['method'][0]
#                yhat_test = matlab_y_predict_test.transpose()[:,0].reshape((-1,1))
#                yhat_test = scaler_y.inverse_transform(yhat_test)
#                
#                fitting_result[selected_model] = {'model_hyper':matlab_params,'final_model':matlab_myresults, 'mse_train':matlab_MSE_train, 'mse_val':matlab_MSE_val, 'mse_test':matlab_MSE_test, 'yhat_train':matlab_y_predict_train, 'yhat_val':matlab_y_predict_val,'yhat_test':matlab_y_predict_test}
#
#                residual_analysis(X_test, y_test,yhat_test, alpha = alpha, round_number = round_number)
#                print('--------------Analysis Is Done--------------')
#                
#            else:
#                print('The final state space model is selected based on minimum averaged MSE.')
#                if np.mean(matlab_MSE_train) <= np.mean(Adaptx_MSE_train):
#                    print('State space model by Matlab is selected. Model parameters is stored in matlab_params.')
#                    print('The final state space model is fitted based on ' + matlab_params['method'][0] + ' using MATLAB.')
#                    selected_model = matlab_params['method'][0]
#                    yhat_test = matlab_y_predict_test.transpose()[:,0].reshape((-1,1))
#                    yhat_test = scaler_y.inverse_transform(yhat_test)
#                    fitting_result[selected_model] = {'model_hyper':matlab_params,'final_model':matlab_myresults, 'mse_train':matlab_MSE_train, 'mse_val':matlab_MSE_val, 'mse_test':matlab_MSE_test, 'yhat_train':matlab_y_predict_train, 'yhat_val':matlab_y_predict_val,'yhat_test':matlab_y_predict_test}
#
#                    residual_analysis(X_test, y_test,yhat_test, alpha = alpha, round_number = round_number)
#                    print('--------------Analysis Is Done--------------')
#                    
#                    
#                else:
#                    print('State space model by ADAPTx is selected. Model parameters is stored in Adaptx_optimal_params.')
#                    selected_model = 'ADAPTx'
#                    yhat_test = Adaptx_y_predict_test.transpose()[Adaptx_optimal_params['lag'][0][0]:,0].reshape((-1,1))
#                    yhat_test = scaler_y.inverse_transform(yhat_test)                
#                    fitting_result[selected_model] = {'model_hyper':Adaptx_optimal_params,'final_model':Adaptx_myresults, 'mse_train':Adaptx_MSE_train, 'mse_val':Adaptx_MSE_val, 'mse_test':Adaptx_MSE_test, 'yhat_train':Adaptx_y_predict_train, 'yhat_val':Adaptx_y_predict_val,'yhat_test':Adaptx_y_predict_test}
#
#                    residual_analysis(X_test[Adaptx_optimal_params['lag'][0][0]:,:], y_test[Adaptx_optimal_params['lag'][0][0]:,0].reshape((-1,1)),yhat_test, alpha = alpha, round_number = round_number)
#                    print('--------------Analysis Is Done--------------')
#

def load_file(filename):
    """
    Used by SPA to load data files.
    """
    _, ext = splitext(filename)
    if ext == '.txt': # Assume is separated by space
        my_file = read_csv(filename, header = None, sep = ' ').values
        for separator in (',', '\t', ';'): # Testing random separators
            if my_file.shape[-1] == 1: # The file likely is not separated by a space
                my_file = read_csv(filename, header = None, sep = separator).values
            else: # We likely found the separator
                break
    elif ext == '.csv':
        my_file = read_csv(filename, header = None, sep = ',').values
    elif ext == '.tsv':
        my_file = read_csv(filename, header = None, sep = '\t').values
    elif ext in {'.xls', '.xlsx'}:
        my_file = read_excel(filename, header = None).values
    else: # TODO: JSON support?
        raise ValueError(f'Please provide a filename with extension in {{.txt, .csv, .tsv, .xls, .xlsx}}. You passed {filename}')
    return my_file

def run_cv_nondynamic(model_index, X_train, y_train, X_train_scaled, y_train_scaled, X_test, y_test, X_test_scaled, y_test_scaled,
                        cv_method, group, K_fold, Nr, alpha_num, for_validation = False):
    """
    Runs a nondynamic model for CV or final-run purposes. Automatically called by SPA.

    Parameters
    ----------
    model_index to alpha_num
        Automatically called by SPA
    for_validation : bool, optional, default = False
        Whether the run is done for validation (to determine the best model),
        or for testing of the model.
        This changes a little the syntax and values returned, but not the logic.
    """
    if for_validation:
        # For the sake of clarity
        X_val, y_val = X_test, y_test
        X_val_scaled, y_val_scaled = X_test_scaled, y_test_scaled

        if model_index == 'ALVEN':
            _, _, _, _, mse_val, _, _, _, _ = cv.CV_mse(model_index, X_train, y_train, X_val, y_val,
                    cv_type = cv_method, group = group, K_fold = K_fold, Nr = Nr, alpha_num = alpha_num, label_name = True)
        elif model_index == 'SVR' or model_index == 'RF':
            _, _, _, mse_val, _, _, _ = cv.CV_mse(model_index, X_train_scaled, y_train_scaled, X_val_scaled, y_val_scaled,
                    cv_type = cv_method, group = group, K_fold = K_fold, Nr = Nr, alpha_num = alpha_num)
        else:
            _, _, _, _, mse_val, _, _, _ = cv.CV_mse(model_index, X_train_scaled, y_train_scaled,
                    X_val_scaled, y_val_scaled, cv_type = cv_method, group = group, K_fold = K_fold, Nr = Nr, alpha_num = alpha_num)
        return mse_val
    else:
        if model_index == 'ALVEN':
            model_hyper, final_model, model_params, mse_train, mse_test, yhat_train, yhat_test, mse_val, final_list = cv.CV_mse(model_index, X_train, y_train, X_test, y_test,
                    cv_type = cv_method, group = group, K_fold = K_fold, Nr = Nr, alpha_num = alpha_num, label_name = True)
            fitting_result = {'model_hyper':model_hyper,'final_model':final_model, 'model_params':model_params, 'mse_train':mse_train, 'mse_test':mse_test,
                    'yhat_train':yhat_train, 'yhat_test':yhat_test, 'mse_val':mse_val, 'final_list':final_list}
        elif model_index == 'SVR' or model_index == 'RF':
            model_hyper, final_model, mse_train, mse_test, yhat_train, yhat_test, mse_val = cv.CV_mse(model_index, X_train_scaled, y_train_scaled, X_test_scaled, y_test_scaled,
                    cv_type = cv_method, group = group, K_fold = K_fold, Nr = Nr, alpha_num = alpha_num)
            fitting_result = {'model_hyper':model_hyper,'final_model':final_model, 'mse_train':mse_train, 'mse_test':mse_test,
                    'yhat_train':yhat_train, 'yhat_test':yhat_test, 'mse_val':mse_val}
        else:
            model_hyper, final_model, model_params, mse_train, mse_test, yhat_train, yhat_test, mse_val = cv.CV_mse(model_index, X_train_scaled, y_train_scaled, X_test_scaled, y_test_scaled,
                    cv_type = cv_method, group = group, K_fold = K_fold, Nr = Nr, alpha_num = alpha_num)
            fitting_result = {'model_hyper':model_hyper,'final_model':final_model, 'model_params':model_params, 'mse_train':mse_train, 'mse_test':mse_test,
                    'yhat_train':yhat_train, 'yhat_test':yhat_test, 'mse_val': mse_val}
        return fitting_result, mse_val

